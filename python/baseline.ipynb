{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baselines\n",
    "\n",
    "Baseline Method Repositories:\n",
    "\n",
    "- https://github.com/xunzheng/notears\n",
    "- https://github.com/fishmoon1234/DAG-GNN\n",
    "- https://github.com/huawei-noah/trustworthyAI\n",
    "- https://github.com/kurowasan/GraN-DAG\n",
    "  - use this: https://github.com/lihebi/GraN-DAG-nodata\n",
    "  - the paper: [Gradient-Based Neural DAG Learning](https://openreview.net/forum?id=rklbKA4YDS)\n",
    "\n",
    "TODOs:\n",
    "- [ ] which uses GPU and which does not\n",
    "- [ ] use covariate matrix\n",
    "- [ ] RL-BIC hyper-parameters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1+2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install -r ../python/requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1+2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Also need to install torch, but it is different on diferent OSes\n",
    "#\n",
    "# pip3 install torch torchvision torchaudio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "sys.path.append(\"/home/jovyan/DAG-EQ/python/pygobnilp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pygobnilp.gobnilp import Gobnilp\n",
    "m = Gobnilp()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m.learn('pygobnilp/data/gaussian.dat',data_type='continuous',score='BGe',plot=False,palim=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m.learned_bn.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datadir = \"../notebooks/data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from baseline import read_hdf5_iter, get_dataset_fname"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fname = get_dataset_fname(datadir, 10, 'SF')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "it = read_hdf5_iter(fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = next(it)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.columns = [str(x) for x in x.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from baseline_cdt import run_CDT\n",
    "from baseline_common import compute_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m._data.data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for score in ['BGe', 'GaussianLL', 'GaussianBIC', 'GaussianAIC', 'GaussianL0']:\n",
    "    print('---- score', score)\n",
    "    m.learn(x, data_type='continuous',score='BGe',plot=False,palim=None)\n",
    "    ypred = nx.to_numpy_matrix(m.learned_bn)\n",
    "    res1 = compute_metrics(ypred, y, isPDAG=True)\n",
    "    res2 = compute_metrics(ypred.transpose(), y, isPDAG=True)\n",
    "    print('--- res  ', res1)\n",
    "    print('--- res.t', res2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'GaussianBIC'\n",
    "# 'BGe'\n",
    "# GaussianLL, GaussianBIC, GaussianAIC and GaussianL0\n",
    "m.learn(x, data_type='continuous',score='BGe',plot=False,palim=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m.learned_bn.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ypred = nx.to_numpy_matrix(m.learned_bn)\n",
    "ypred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute metrics\n",
    "compute_metrics(ypred.transpose(), y, isPDAG=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from baseline import table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from baseline import load_results, get_dataset_fname"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "def table():\n",
    "    # generate table for paper\n",
    "    res = load_results()\n",
    "    # generate csv directly\n",
    "    # csv.write()\n",
    "    with open('results/method.csv', 'w') as fp:\n",
    "        writer = csv.writer(fp)\n",
    "        # header\n",
    "        writer.writerow(['model', 'prec', 'recall', 'shd', 'time'])\n",
    "        for d in [10, 20, 50, 100, 200, 300, 400]:\n",
    "            print('d', d)\n",
    "            nameSF = get_dataset_fname('../notebooks/data', d, 'SF')\n",
    "            nameER = get_dataset_fname('../notebooks/data', d, 'ER')\n",
    "            methods = ['PC', 'GES', \n",
    "                       'CAM',\n",
    "#                        'RCC-CLF', 'RCC-NN',\n",
    "#                        'notears',\n",
    "#                        'DAG-GNN'\n",
    "                       ]\n",
    "            for method in methods:\n",
    "                if method in res[nameSF] and method in res[nameER]:\n",
    "                    tmp = np.mean([res[nameSF][method], res[nameER][method]], axis=0).tolist()\n",
    "                    tmp = ['{:.1f}'.format(tmp[0] * 100),\n",
    "                           '{:.1f}'.format(tmp[1] * 100),\n",
    "                           tmp[2],\n",
    "                           '{:.2f}'.format(tmp[3])]\n",
    "                    # tmp = list(map(lambda x: '{:.3f}'.format(x), tmp))\n",
    "                    tmp = [method] + tmp\n",
    "                    print(tmp)\n",
    "                    writer.writerow(tmp)\n",
    "            writer.writerow([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# random testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean([[1,2,3], [1,2,3]], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list((1,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.ones((3,3)).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a,b = [1,2,3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup\n",
    "\n",
    "Python libraries:\n",
    "\n",
    "```\n",
    "pip install -r requirements.txt\n",
    "```\n",
    "\n",
    "Download some repos\n",
    "\n",
    "```\n",
    "git clone https://github.com/xunzheng/notears\n",
    "git clone https://github.com/fishmoon1234/DAG-GNN\n",
    "# This is repo is broken, too large to clone\n",
    "git clone https://github.com/kurowasan/GraN-DAG\n",
    "git clone https://github.com/huawei-noah/trustworthyAI\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install -i https://pypi.tuna.tsinghua.edu.cn/simple -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## R packages (this is so unhumanity)\n",
    "\n",
    "\n",
    "- this will consume a lot of network traffic. Need to be careful when using proxy\n",
    "- this needs some time for compilation\n",
    "\n",
    "```\n",
    "# graph is not available in default repo\n",
    "> install.packages(\"BiocManager\")\n",
    "# dependencies for pcalg\n",
    "> BiocManager::install(\"graph\")\n",
    "> BiocManager::install(\"RBGL\")\n",
    "\n",
    "> install.packages(\"pcalg\")\n",
    "> install.packages(\"kpcalg\")\n",
    "> BiocManager::install(\"usethis\")\n",
    "> install.packages(\"devtools\")\n",
    "> library(devtools)\n",
    "> install_github(\"Diviyan-Kalainathan/RCIT\")\n",
    "> library(RCIT)\n",
    "```\n",
    "\n",
    "CAM needs to be downloaded and install from file.\n",
    "\n",
    "```\n",
    "> install.packages(\"/path/to/CAM_1.0.tar.gz\")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!R --version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The python repos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/xunzheng/notears.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/fishmoon1234/DAG-GNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.path.abspath(\"./notears\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(os.path.abspath(\"./notears\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from notears.linear import notears_linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(os.path.abspath(\"./DAG-GNN/src\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from baseline_daggnn import dag_gnn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FIXME no GPU detected\n",
    "# No GPU automatically detected. Setting SETTINGS.GPU to 0, and SETTINGS.NJOBS to cpu_count.\n",
    "# that is caused by causal_discovery_toolbox/cdt/utils/Settings.py\n",
    "from baseline import run_many, main, table, get_dataset_fname"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing baselines individually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datadir = \"../notebooks/data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_dataset_fname(datadir, 10, \"ER\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_baseline(alg, d, gtype):\n",
    "    run_many(alg, get_dataset_fname(datadir, d, gtype))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_baseline('gob', d=10, gtype='ER')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "run_baseline('PC', d=10, gtype='ER')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls ../notebooks/data/ER-10-ng=3000-1234"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OK, let's run notears ..\n",
    "run_baseline('notears', d=10, gtype='SF')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "run_baseline('GES', d=10, gtype='SF')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "run_baseline('CAM', d=10, gtype='SF')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "run_baseline('RCC-CLF', d=10, gtype='SF')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "run_baseline('RCC-NN', d=10, gtype='SF')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "run_baseline('DAG-GNN', d=10, gtype='SF')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RL-BIC requires tensorflow 1, so ..\n",
    "#\n",
    "# UPDATE: tensorflow 1 only supports python up to 3.7\n",
    "#\n",
    "# UPDATE I'm not reporting RL-BIC\n",
    "!pip uninstall --yes tensorflow\n",
    "!pip install tensorflow-gpu==1.15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FIXME hyper-parameters\n",
    "# FIXME tensorflow 1 compatibility\n",
    "run_baseline('RL-BIC', d=10, gtype='SF')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The PDAGs\n",
    "\n",
    "What algorithms generate PDAGs?\n",
    "- PC\n",
    "- GES\n",
    "- CAM\n",
    "\n",
    "The output is a matrix (TODO verify the undirected edges). So if it is a PDAG, how should I compute the matrix?\n",
    "- For undirected edges, as long as there's an edge predicted, count as true, (once or twice?).\n",
    "- If once, I probably need to report FDR and TPR consistent to NOTEARS paper\n",
    "- well, let's consider twice to be CONSISTENT with my current result\n",
    "  - For directed edges, it will generate 2 cases\n",
    "  - For undirected edges, it will also generate 2 cases.\n",
    "    - If there's an edge in true graph, 2 correct\n",
    "    - If there's no edge, 2 incorrect\n",
    "    - Previous\n",
    "      - an edge in true graph: 1 correct 1 incorrect\n",
    "      - no edge in true graph: 1 correct 1 incorrect\n",
    "      - So really, the performance can be better or worse. But most likely it will be better, because the undirected edge should be correct.\n",
    "  - For no-edge, it will generate 2 cases\n",
    "    - If there's an edge in true graph, 1 correct 1 incorrect\n",
    "    - Else, 1 correct, 1 incorrect\n",
    "    - This looks weird. So if output an empty graph, it would be 0.5 prec and 0.5 recall\n",
    "\n",
    "From notears:\n",
    "\n",
    "> Thus, in our evaluations, we treated FGS favourably by treating undirected edges as true\n",
    "> positives as long as the true graph had a directed edge in place of the undirected edge.\n",
    "\n",
    "Also, the RCC is pairwise method. Not sure if I should use special treatment? Probably not.\n",
    "\n",
    "Besides, TODO DAG-EQ outputs DAGs, but should I give some treatment for PDAGs as well? If it is up to equivalent class, there's no expectation for DAG-EQ to find the exact graph.\n",
    "- I could allow DAG-EQ to output bidirectional edges, and treat it as one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from baseline import read_hdf5_iter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fname = get_dataset_fname(datadir, 10, 'SF')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "it = read_hdf5_iter(fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = next(it)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from baseline_cdt import run_CDT\n",
    "from baseline_common import compute_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. run PC\n",
    "# run_many(alg, get_dataset_fname(datadir, d, gtype))\n",
    "mat = run_CDT('PC', x, y, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. examine the matrix: how many undirected edges\n",
    "# just plot it\n",
    "g = nx.to_networkx_graph(mat,create_using=nx.DiGraph()) \n",
    "nx.draw_networkx(g, pos=nx.spring_layout(g, seed=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = nx.to_networkx_graph(y,create_using=nx.DiGraph()) \n",
    "nx.draw_networkx(g, pos=nx.spring_layout(g, seed=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. compute metrics before\n",
    "prec, recall, shd = compute_metrics(mat, y)\n",
    "print('prec:', prec, 'recall:', recall, 'shd:', shd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. compute metrics after\n",
    "# FIXME seems to be 0.5 dominately\n",
    "prec, recall, shd = compute_metrics(mat, y, True)\n",
    "print('prec:', prec, 'recall:', recall, 'shd:', shd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "notears_linear(np.array(x), lambda1=0, loss_type='l2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run on SynTRen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the data and true graph\n",
    "fname = \"data/syntren/hop0/nn20_nbgr0_hop0.0_bionoise0.1_expnoise0.1_corrnoise0.1_neighAdd_unnormalized_dataset.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(fname, sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.transpose()[1:].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load ground truth graph\n",
    "gfname = \"data/syntren/hop0/nn20_nbgr0_hop0.0_bionoise0.1_expnoise0.1_corrnoise0.1_neighAdd_network.sif\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g.nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = nx.DiGraph()\n",
    "# add all the nodes in order\n",
    "for name in df['GENE']:\n",
    "    g.add_node(name)\n",
    "with open(gfname) as fp:\n",
    "    for line in fp:\n",
    "        frm, rel, to = line.split()\n",
    "        if frm == to: continue\n",
    "        if rel == \"ac\":\n",
    "            g.add_edge(frm, to)\n",
    "        elif rel == 're':\n",
    "            g.add_edge(frm, to)\n",
    "        elif rel == 'du':\n",
    "            g.add_edge(frm, to)\n",
    "            g.add_edge(to, frm)\n",
    "        else:\n",
    "            # FIXME\n",
    "            raise Exception('Error: unsupported relation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.draw_circular(g, with_labels=True, node_color=\"white\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g.adj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g.nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = nx.adjacency_matrix(g).todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from notears.linear import notears_linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mat = notears_linear(np.array(X, dtype=np.float), lambda1=0, loss_type='l2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mat = (mat != 0).astype(np.int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from baseline_common import compute_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prec, recall, shd = compute_metrics(mat, Y.transpose())\n",
    "prec, recall, shd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prec, recall, shd = compute_metrics(mat, Y)\n",
    "prec, recall, shd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# draw the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(X, dtype=np.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run NOTEARS\n",
    "\n",
    "mat = (mat != 0).astype(np.int)\n",
    "# CAUTION here seems that I must do y.transpose()\n",
    "prec, recall, shd = compute_metrics(mat, y.transpose())\n",
    "print('prec:', prec, 'recall:', recall, 'shd:', shd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## testing networkX library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = nx.DiGraph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g.is_directed()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g.add_node(\"hello\")\n",
    "g.add_node(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g.add_edge(3, \"hello\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g.add_edge(\"hello\", 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.draw(g, pos=nx.spring_layout(g), with_labels=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos = nx.spring_layout(g)\n",
    "nx.draw_networkx_nodes(g, pos, node_color='white', edgecolors='black')\n",
    "nx.draw_networkx_edges(g, pos, arrowsize=20)\n",
    "# for p in pos:  # raise text positions\n",
    "#     pos[p][1] += 0.1\n",
    "nx.draw_networkx_labels(g, pos, font_color='red')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the daemon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FIXME no GPU detected\n",
    "from baseline import run_many, main, table, get_dataset_fname"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from baseline import get_dataset_fname_old, load_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO generate table suitable for view\n",
    "# TODO save the view\n",
    "table()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pdtable():\n",
    "    res = load_results()\n",
    "    # generate csv directly\n",
    "    # csv.write()\n",
    "    with open('results/method.csv', 'w') as fp:\n",
    "        writer = csv.writer(fp)\n",
    "        # header\n",
    "        writer.writerow(['model', 'prec', 'recall', 'shd', 'time'])\n",
    "        for d in [10, 20, 50, 100]:\n",
    "            # CAUTION fixed \"SF\" here\n",
    "            #\n",
    "            # FIXME reading previous results\n",
    "            name = get_dataset_fname_old(d, 'SF')\n",
    "            methods = ['PC', 'GES', \n",
    "                       # CAM is a little slow\n",
    "#                        'CAM',\n",
    "                       'RCC-CLF', 'RCC-NN',\n",
    "                       'notears', 'DAG-GNN']\n",
    "#             if d < 50:\n",
    "#                 methods += ['RL-BIC']\n",
    "            for method in methods:\n",
    "                tmp = res[name][method]\n",
    "                tmp = ['{:.1f}'.format(tmp[0] * 100),\n",
    "                       '{:.1f}'.format(tmp[1] * 100),\n",
    "                       tmp[2],\n",
    "                       '{:.2f}'.format(tmp[3])]\n",
    "                # tmp = list(map(lambda x: '{:.3f}'.format(x), tmp))\n",
    "                tmp = [method] + tmp\n",
    "                writer.writerow(tmp)\n",
    "            writer.writerow([])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = load_results()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(columns=['method', 'd', 'prec', 'recall', 'shd'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "row1 = {'method': 'test', 'd': 5, 'prec': 0.3, 'recall': 0.23, 'shd': 23}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.append(row1, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(columns=['method', 'd', 'prec', 'recall', 'shd'])\n",
    "for d in [10,20,50,100]:\n",
    "    name_sf = get_dataset_fname_old(d, 'SF')\n",
    "    name_er = get_dataset_fname_old(d, 'ER')\n",
    "    for method in ['PC', 'GES', 'RCC-CLF', 'RCC-NN', 'notears', 'DAG-GNN']:\n",
    "        tmp_sf = result[name_sf][method]\n",
    "        tmp_er = result[name_er][method]\n",
    "        df = df.append({'method': method,\n",
    "                  'd': d,\n",
    "                  'prec': '{:.1f}'.format((tmp_sf[0] + tmp_er[0]) / 2 * 100),\n",
    "                  'recall': '{:.1f}'.format((tmp_sf[1] + tmp_er[1]) / 2 * 100),\n",
    "                  'shd': '{:.2f}'.format((tmp_sf[2] + tmp_er[2]) / 2)},\n",
    "                      ignore_index=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Playground"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Disabling cuda\n",
    "\n",
    "My intention is to globally set whether to use cuda or not. The code has xxxtensor.cuda(), so that I can globally turn on cuda without changing the code. The motivation is that DAG-GNN has its layer creating CPU tensors, and that would throw error when computing with CUDA tensors. I can disable .cuda() semantics to be compatible with DAG-GNN's code without modifying it.\n",
    "\n",
    "UPDATE: I still need to check `torch.cuda.is_available()` before calling `tensor.cuda()`, otherwise exception is thrown. I'm not using this, and instead disabled `.cuda()` calls by `use_cuda` variable in `baseline_daggnn.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This must be run before any torch API calls\n",
    "os.putenv('CUDA_VISIBLE_DEVICES', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.getenv('CUDA_VISIBLE_DEVICES')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.current_device()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.device(None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.device_count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing pygobnilp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!export HTTPS_PROXY=\"http://172.18.0.1:8889\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pygobnilp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pygobnilp.gobnilp import Gobnilp\n",
    "m = Gobnilp()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m.learn('/home/jovyan/data/gaussian.dat',data_type='continuous',score='BGe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m.learn('discrete.dat')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
