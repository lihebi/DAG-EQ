{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "versioninfo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g=6.0\n",
    "ENV[\"JULIA_CUDA_MEMORY_LIMIT\"] = convert(Int, round(g * 1024 * 1024 * 1024))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ENV[\"JULIA_DEBUG\"]=\"all\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# New version of main\n",
    "\n",
    "- [X] refactor the code of main1\n",
    "- [X] use seeding\n",
    "- [X] pre-gen graphs and splitting\n",
    "- [X] use cloud GPU for training\n",
    "- [X] I don't need correlation experiments anymore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1+2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "main (generic function with 1 method)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "include(\"main.jl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_ngraph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_ersf124()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_ch3()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "main_cnn (generic function with 1 method)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function main_cnn()\n",
    "    for d in [10,20,50],\n",
    "        (prefix, model_fn,nsteps) in [\n",
    "#             (\"CNN\", ()->cnn_model(2), 3e4),\n",
    "            (\"CNN2-$(now())\", ()->cnn_model(2, 128, (5,5), (2,2)), 3e4),\n",
    "#             (\"CNN2\", ()->cnn_model(2, 128, (3,3), (1,1)), 3e4)\n",
    "        ]\n",
    "        \n",
    "        specs = []\n",
    "        for gtype in [:ER, :SF],\n",
    "            k in [1]\n",
    "            push!(specs, DataSpec(d=d, k=k, gtype=gtype,\n",
    "                    noise=:Gaussian, mat=:CH3,\n",
    "                    ng=10000, N=1))\n",
    "        end\n",
    "        specs = Array{DataSpec}(specs)\n",
    "        \n",
    "        # print more frequently for CNN and FC to get more data to print\n",
    "        test_throttle = if prefix == \"EQ2\" 10 else 1 end\n",
    "\n",
    "        @info \"training ..\" prefix d\n",
    "        expID = exp_train(specs, model_fn,\n",
    "                          # TODO I'll need to increase the training steps here\n",
    "                          # CAUTION feed in the gtype in the model prefix\n",
    "                          prefix=\"$prefix-ERSF-k1-d=$d\", train_steps=nsteps,\n",
    "                          test_throttle = test_throttle,\n",
    "                          merge=true)\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: training ..\n",
      "│   prefix = CNN2-2021-01-20T15:40:39.803\n",
      "│   d = 10\n",
      "└ @ Main In[6]:21\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(xdim, ydim) = (4, 3)\n",
      "(xdim, ydim) = (4, 3)\n",
      "ds = DataSetIterator[DataSetIterator:\n",
      "  batch size: 64\n",
      "  number of batches: 250\n",
      "  x data shape: (10, 10, 2, 16000)\n",
      "  y data shape: (10, 10, 16000)\n",
      "  current index: 1]\n",
      "test_ds = DataSetIterator[DataSetIterator:\n",
      "  batch size: 64\n",
      "  number of batches: 62\n",
      "  x data shape: (10, 10, 2, 4002)\n",
      "  y data shape: (10, 10, 4002)\n",
      "  current index: 1]\n",
      "size(x) = (10, 10, 2, 64)\n",
      "size(y) = (10, 10, 64)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: warming up model with x ..\n",
      "└ @ Main /home/hebi/git/DAG-EQ/src/exp.jl:143\n",
      "┌ Info: warming up gradient ..\n",
      "└ @ Main /home/hebi/git/DAG-EQ/src/exp.jl:145\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size(x) = (10, 10, 2, 64)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: actual training ..\n",
      "└ @ Main /home/hebi/git/DAG-EQ/src/exp.jl:148\n",
      "┌ Info: training ..\n",
      "└ @ Main /home/hebi/git/DAG-EQ/src/exp.jl:166\n",
      "┌ Info: training for 30000 steps ..\n",
      "└ @ Main /home/hebi/git/DAG-EQ/src/train.jl:222\n",
      "┌ Warning: calls to Base intrinsics might be GPU incompatible\n",
      "│   exception = (GPUCompiler.MethodSubstitutionWarning(log1p(x::Float32) in Base.Math at special/log.jl:360, log1p(x::Float32) in CUDA at /home/hebi/.julia/packages/CUDA/YeS8q/src/device/intrinsics/math.jl:85), Base.StackTraces.StackFrame[log1p at log.jl:360, broadcast_kernel at broadcast.jl:59])\n",
      "└ @ GPUCompiler /home/hebi/.julia/packages/GPUCompiler/uTpNx/src/irgen.jl:68\n",
      "┌ Warning: calls to Base intrinsics might be GPU incompatible\n",
      "│   exception = (GPUCompiler.MethodSubstitutionWarning(log1p(x::Float32) in Base.Math at special/log.jl:360, log1p(x::Float32) in CUDA at /home/hebi/.julia/packages/CUDA/YeS8q/src/device/intrinsics/math.jl:85), Base.StackTraces.StackFrame[log1p at log.jl:360, broadcast_kernel at broadcast.jl:59])\n",
      "└ @ GPUCompiler /home/hebi/.julia/packages/GPUCompiler/uTpNx/src/irgen.jl:68\n",
      "\u001b[32mTraining...100%|████████████████████████████████████████| Time: 0:11:58\u001b[39mm:57\u001b[39m\n",
      "┌ Info: training ..\n",
      "│   prefix = CNN2-2021-01-20T15:53:27.09\n",
      "│   d = 20\n",
      "└ @ Main In[6]:21\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(xdim, ydim) = (4, 3)\n",
      "(xdim, ydim) = (4, 3)\n",
      "ds = DataSetIterator[DataSetIterator:\n",
      "  batch size: 64\n",
      "  number of batches: 250\n",
      "  x data shape: (20, 20, 2, 16000)\n",
      "  y data shape: (20, 20, 16000)\n",
      "  current index: 1]\n",
      "test_ds = DataSetIterator[DataSetIterator:\n",
      "  batch size: 64\n",
      "  number of batches: 62\n",
      "  x data shape: (20, 20, 2, 4002)\n",
      "  y data shape: (20, 20, 4002)\n",
      "  current index: 1]\n",
      "size(x) = (20, 20, 2, 64)\n",
      "size(y) = (20, 20, 64)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: warming up model with x ..\n",
      "└ @ Main /home/hebi/git/DAG-EQ/src/exp.jl:143\n",
      "┌ Info: warming up gradient ..\n",
      "└ @ Main /home/hebi/git/DAG-EQ/src/exp.jl:145\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size(x) = (20, 20, 2, 64)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: actual training ..\n",
      "└ @ Main /home/hebi/git/DAG-EQ/src/exp.jl:148\n",
      "┌ Info: training ..\n",
      "└ @ Main /home/hebi/git/DAG-EQ/src/exp.jl:166\n",
      "┌ Info: training for 30000 steps ..\n",
      "└ @ Main /home/hebi/git/DAG-EQ/src/train.jl:222\n",
      "\u001b[32mTraining... 48%|███████████████████▏                    |  ETA: 0:30:08\u001b[39mm"
     ]
    }
   ],
   "source": [
    "main_cnn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_mat()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_ensemble_d()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DEBUG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ensemble\n",
    "\n",
    "- [ ] I actually probably want to merge the datasets with the same d.\n",
    "  This is because, I can merge the data to be more evenly distributed to fit the model.\n",
    "- [ ] I probably want to adjust batch size to speed it up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = eq_model_fn() |> gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds, test_ds = spec2ds(DataSpec(d=20, k=1, gtype=:ER,\n",
    "                    noise=:Gaussian, mat=:COV))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = next_batch!(test_ds) |> gpu\n",
    "\n",
    "@show size(x)\n",
    "@show size(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# model params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "main (generic function with 1 method)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "include(\"main.jl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import Printf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function test_size()\n",
    "    # model size\n",
    "    @info \"FC model\"\n",
    "    for d in [10,20,50,100]\n",
    "        Printf.@printf \"%.2f\\n\" param_count(fc_model_fn(d)) / 1e6\n",
    "    end\n",
    "    @info \"FC deep model\"\n",
    "    for d in [7, 10,15,20,25,30]\n",
    "        Printf.@printf \"%.2f\\n\" param_count(deep_fc_model_fn(d)) / 1e6\n",
    "    end\n",
    "    # EQ models is independent of input size\n",
    "    @info \"EQ model\"\n",
    "    Printf.@printf \"%.2f\\n\" param_count(eq_model_fn(10)) / 1e6\n",
    "    Printf.@printf \"%.2f\\n\" param_count(deep_eq_model_fn(10)) / 1e6\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "            (\"EQ2\", eq2_model_fn, 3e4),\n",
    "            (\"FC\", ()->fc_model(d=d, ch=2, z=1024, nlayer=6), 3e4),\n",
    "            (\"FCreg\", ()->fc_model(d=d, ch=2, z=1024, nlayer=6, reg=true), 3e4),\n",
    "            (\"CNN\", ()->cnn_model(2), 3e4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.51\n",
      "5.43\n",
      "11.88\n",
      "34.93\n"
     ]
    }
   ],
   "source": [
    "for d in [10,20,50,100]\n",
    "    Printf.@printf \"%.2f\\n\" param_count(fc_model(d=d, ch=2, z=1024, nlayer=6)) / 1e6\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.45\n"
     ]
    }
   ],
   "source": [
    "Printf.@printf \"%.2f\\n\" param_count(eq2_model_fn()) / 1e6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.36\n"
     ]
    }
   ],
   "source": [
    "Printf.@printf \"%.2f\\n\" param_count(eq_model_fn()) / 1e6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.04\n"
     ]
    }
   ],
   "source": [
    "Printf.@printf \"%.2f\\n\" param_count(cnn_model(2)) / 1e6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "cnn_model (generic function with 5 methods)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.04\n"
     ]
    }
   ],
   "source": [
    "Printf.@printf \"%.2f\\n\" param_count(cnn_model(1, 32)) / 1e6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.04\n"
     ]
    }
   ],
   "source": [
    "Printf.@printf \"%.2f\\n\" param_count(cnn_model(2, 32)) / 1e6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.15\n"
     ]
    }
   ],
   "source": [
    "Printf.@printf \"%.2f\\n\" param_count(cnn_model(2, 64)) / 1e6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.60\n"
     ]
    }
   ],
   "source": [
    "Printf.@printf \"%.2f\\n\" param_count(cnn_model(2, 128)) / 1e6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.11\n"
     ]
    }
   ],
   "source": [
    "Printf.@printf \"%.2f\\n\" param_count(cnn_model(2, 32, (5,5), (2,2))) / 1e6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.42\n"
     ]
    }
   ],
   "source": [
    "Printf.@printf \"%.2f\\n\" param_count(cnn_model(2, 64, (5,5), (2,2))) / 1e6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.65\n"
     ]
    }
   ],
   "source": [
    "Printf.@printf \"%.2f\\n\" param_count(cnn_model(2, 128, (5,5), (2,2))) / 1e6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test ERSF124 on individual types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "test_ersf124 (generic function with 1 method)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function test_ersf124()\n",
    "    for d in [10, 20],\n",
    "        types in [(:ER, :SF), (:ER2, :SF2), (:ER4, :SF4)]\n",
    "        \n",
    "        ID = \"EQ2-ERSF124-d=$d-ensemble\"\n",
    "\n",
    "        specs = []\n",
    "\n",
    "        for gtype in types,\n",
    "            k in [1]\n",
    "            push!(specs, DataSpec(d=d, k=k, gtype=gtype,\n",
    "                                  noise=:Gaussian, mat=:CH3))\n",
    "        end\n",
    "        specs = Array{DataSpec}(specs)\n",
    "\n",
    "        exp_test(ID, specs, \"TEST-types=$types\")\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ersf124()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test the ensemble model on unseen d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# can I just run the test without saving? No because loading the main.jl is slow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "main (generic function with 1 method)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "include(\"main.jl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "test_unseen_d (generic function with 1 method)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function test_unseen_d()\n",
    "    for ID in [\"EQ2-CH3-d=[10,15,20]-ensemble\",\"EQ2-CH3-d=[20,30,40]-ensemble\"],\n",
    "        d in [10, 15, 20, 30, 40, 50, 80, 100]\n",
    "\n",
    "        specs = []\n",
    "\n",
    "        for gtype in [:ER, :SF],\n",
    "            k in [1]\n",
    "            push!(specs, DataSpec(d=d, k=k, gtype=gtype,\n",
    "                                  noise=:Gaussian, mat=:CH3))\n",
    "        end\n",
    "        specs = Array{DataSpec}(specs)\n",
    "\n",
    "        exp_test(ID, specs, \"TEST-d=$d\")\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size(mats) = (1600,)\n",
      "size(mats[1]) = (30, 30)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Loading step-30000.bson ..\n",
      "└ @ Main /home/hebi/git/DAG-EQ/src/exp.jl:38\n",
      "┌ Info: Generating graphs for \n",
      "│   spec = DataSpec(30, 1, :ER, :Gaussian, :CH3, :Linear, 2000, 2, 64, 1234)\n",
      "└ @ Main /home/hebi/git/DAG-EQ/src/data_graph.jl:568\n",
      "┌ Info: concating ..\n",
      "└ @ Main /home/hebi/git/DAG-EQ/src/data_graph.jl:517\n",
      "┌ Info: done\n",
      "└ @ Main /home/hebi/git/DAG-EQ/src/data_graph.jl:520\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size(mats) = (401,)\n",
      "size(mats[1]) = (30, 30)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: concating ..\n",
      "└ @ Main /home/hebi/git/DAG-EQ/src/data_graph.jl:517\n",
      "┌ Info: done\n",
      "└ @ Main /home/hebi/git/DAG-EQ/src/data_graph.jl:520\n",
      "┌ Info: generating training ds ..\n",
      "└ @ Main /home/hebi/git/DAG-EQ/src/data_graph.jl:597\n",
      "\u001b[32mGenerating..100%|███████████████████████████████████████| Time: 0:00:01\u001b[39m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size(input) = (1600,)\n",
      "size(input[1]) = (30, 30, 2, 2)\n",
      "size(output) = (1600,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: generating testing ds ..\n",
      "└ @ Main /home/hebi/git/DAG-EQ/src/data_graph.jl:599\n",
      "\u001b[32mGenerating..100%|███████████████████████████████████████| Time: 0:00:00\u001b[39m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size(input) = (401,)\n",
      "size(input[1]) = (30, 30, 2, 2)\n",
      "size(output) = (401,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mGenerating raw XY ..100%|███████████████████████████████| Time: 0:00:00\u001b[39m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size(mats) = (1600,)\n",
      "size(mats[1]) = (30, 30)\n",
      "size(mats) = (401,)\n",
      "size(mats[1]) = (30, 30)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Saved to data/ER-30-ng=2000-1234/d=30_k=1_gtype=ER_noise=Gaussian_mat=CH3_mec=Linear_ng=2000_N=2.hdf5\n",
      "└ @ Main /home/hebi/git/DAG-EQ/src/data_graph.jl:616\n",
      "┌ Info: Generating graphs for \n",
      "│   spec = DataSpec(30, 1, :SF, :Gaussian, :CH3, :Linear, 2000, 2, 64, 1234)\n",
      "└ @ Main /home/hebi/git/DAG-EQ/src/data_graph.jl:568\n",
      "┌ Info: concating ..\n",
      "└ @ Main /home/hebi/git/DAG-EQ/src/data_graph.jl:517\n",
      "┌ Info: done\n",
      "└ @ Main /home/hebi/git/DAG-EQ/src/data_graph.jl:520\n",
      "┌ Info: concating ..\n",
      "└ @ Main /home/hebi/git/DAG-EQ/src/data_graph.jl:517\n",
      "┌ Info: done\n",
      "└ @ Main /home/hebi/git/DAG-EQ/src/data_graph.jl:520\n",
      "┌ Info: generating training ds ..\n",
      "└ @ Main /home/hebi/git/DAG-EQ/src/data_graph.jl:597\n",
      "\u001b[32mGenerating..100%|███████████████████████████████████████| Time: 0:00:01\u001b[39m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size(input) = (1600,)\n",
      "size(input[1]) = (30, 30, 2, 2)\n",
      "size(output) = (1600,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: generating testing ds ..\n",
      "└ @ Main /home/hebi/git/DAG-EQ/src/data_graph.jl:599\n",
      "\u001b[32mGenerating..100%|███████████████████████████████████████| Time: 0:00:00\u001b[39m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size(input) = (401,)\n",
      "size(input[1]) = (30, 30, 2, 2)\n",
      "size(output) = (401,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mGenerating raw XY ..100%|███████████████████████████████| Time: 0:00:00\u001b[39m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(xdim, ydim) = (4, 3)\n",
      "(xdim, ydim) = (4, 3)\n",
      "ds = DataSetIterator[DataSetIterator:\n",
      "  batch size: 64\n",
      "  number of batches: 100\n",
      "  x data shape: (30, 30, 2, 6400)\n",
      "  y data shape: (30, 30, 6400)\n",
      "  current index: 1]\n",
      "test_ds = DataSetIterator[DataSetIterator:\n",
      "  batch size: 64\n",
      "  number of batches: 25\n",
      "  x data shape: (30, 30, 2, 1604)\n",
      "  y data shape: (30, 30, 1604)\n",
      "  current index: 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Saved to data/SF-30-ng=2000-1234/d=30_k=1_gtype=SF_noise=Gaussian_mat=CH3_mec=Linear_ng=2000_N=2.hdf5\n",
      "└ @ Main /home/hebi/git/DAG-EQ/src/data_graph.jl:616\n",
      "\u001b[32mInner testing...100%|███████████████████████████████████| Time: 0:00:02\u001b[39m\n",
      "┌ Info: data\n",
      "│   g_v = GraphMetric: prec: 0.91, recall: 0.89, shd: 5.82\n",
      "│   loss_v = 15.716579675674438\n",
      "└ @ Main /home/hebi/git/DAG-EQ/src/train.jl:128\n",
      "┌ Info: Saving results ..\n",
      "└ @ Main In[4]:41\n",
      "┌ Info: Loading step-30000.bson ..\n",
      "└ @ Main /home/hebi/git/DAG-EQ/src/exp.jl:38\n",
      "┌ Info: Generating graphs for \n",
      "│   spec = DataSpec(40, 1, :ER, :Gaussian, :CH3, :Linear, 2000, 2, 64, 1234)\n",
      "└ @ Main /home/hebi/git/DAG-EQ/src/data_graph.jl:568\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size(mats) = (1600,)\n",
      "size(mats[1]) = (40, 40)\n",
      "size(mats) = (401,)\n",
      "size(mats[1]) = (40, 40)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: concating ..\n",
      "└ @ Main /home/hebi/git/DAG-EQ/src/data_graph.jl:517\n",
      "┌ Info: done\n",
      "└ @ Main /home/hebi/git/DAG-EQ/src/data_graph.jl:520\n",
      "┌ Info: concating ..\n",
      "└ @ Main /home/hebi/git/DAG-EQ/src/data_graph.jl:517\n",
      "┌ Info: done\n",
      "└ @ Main /home/hebi/git/DAG-EQ/src/data_graph.jl:520\n",
      "┌ Info: generating training ds ..\n",
      "└ @ Main /home/hebi/git/DAG-EQ/src/data_graph.jl:597\n",
      "\u001b[32mGenerating..100%|███████████████████████████████████████| Time: 0:00:02\u001b[39m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size(input) = (1600,)\n",
      "size(input[1]) = (40, 40, 2, 2)\n",
      "size(output) = (1600,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: generating testing ds ..\n",
      "└ @ Main /home/hebi/git/DAG-EQ/src/data_graph.jl:599\n",
      "\u001b[32mGenerating..100%|███████████████████████████████████████| Time: 0:00:01\u001b[39m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size(input) = (401,)\n",
      "size(input[1]) = (40, 40, 2, 2)\n",
      "size(output) = (401,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mGenerating raw XY ..100%|███████████████████████████████| Time: 0:00:00\u001b[39m\n",
      "┌ Info: Saved to data/ER-40-ng=2000-1234/d=40_k=1_gtype=ER_noise=Gaussian_mat=CH3_mec=Linear_ng=2000_N=2.hdf5\n",
      "└ @ Main /home/hebi/git/DAG-EQ/src/data_graph.jl:616\n",
      "┌ Info: Generating graphs for \n",
      "│   spec = DataSpec(40, 1, :SF, :Gaussian, :CH3, :Linear, 2000, 2, 64, 1234)\n",
      "└ @ Main /home/hebi/git/DAG-EQ/src/data_graph.jl:568\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size(mats) = (1600,)\n",
      "size(mats[1]) = (40, 40)\n",
      "size(mats) = (401,)\n",
      "size(mats[1]) = (40, 40)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: concating ..\n",
      "└ @ Main /home/hebi/git/DAG-EQ/src/data_graph.jl:517\n",
      "┌ Info: done\n",
      "└ @ Main /home/hebi/git/DAG-EQ/src/data_graph.jl:520\n",
      "┌ Info: concating ..\n",
      "└ @ Main /home/hebi/git/DAG-EQ/src/data_graph.jl:517\n",
      "┌ Info: done\n",
      "└ @ Main /home/hebi/git/DAG-EQ/src/data_graph.jl:520\n",
      "┌ Info: generating training ds ..\n",
      "└ @ Main /home/hebi/git/DAG-EQ/src/data_graph.jl:597\n",
      "\u001b[32mGenerating..100%|███████████████████████████████████████| Time: 0:00:02\u001b[39m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size(input) = (1600,)\n",
      "size(input[1]) = (40, 40, 2, 2)\n",
      "size(output) = (1600,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: generating testing ds ..\n",
      "└ @ Main /home/hebi/git/DAG-EQ/src/data_graph.jl:599\n",
      "\u001b[32mGenerating..100%|███████████████████████████████████████| Time: 0:00:00\u001b[39m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size(input) = (401,)\n",
      "size(input[1]) = (40, 40, 2, 2)\n",
      "size(output) = (401,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mGenerating raw XY ..100%|███████████████████████████████| Time: 0:00:00\u001b[39m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(xdim, ydim) = (4, 3)\n",
      "(xdim, ydim) = "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Saved to data/SF-40-ng=2000-1234/d=40_k=1_gtype=SF_noise=Gaussian_mat=CH3_mec=Linear_ng=2000_N=2.hdf5\n",
      "└ @ Main /home/hebi/git/DAG-EQ/src/data_graph.jl:616\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 3)\n",
      "ds = DataSetIterator[DataSetIterator:\n",
      "  batch size: 64\n",
      "  number of batches: 100\n",
      "  x data shape: (40, 40, 2, 6400)\n",
      "  y data shape: (40, 40, 6400)\n",
      "  current index: 1]\n",
      "test_ds = DataSetIterator[DataSetIterator:\n",
      "  batch size: 64\n",
      "  number of batches: 25\n",
      "  x data shape: (40, 40, 2, 1604)\n",
      "  y data shape: (40, 40, 1604)\n",
      "  current index: 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mInner testing...100%|███████████████████████████████████| Time: 0:00:08\u001b[39m\n",
      "┌ Info: data\n",
      "│   g_v = GraphMetric: prec: 0.84, recall: 0.86, shd: 11.83\n",
      "│   loss_v = 32.4844845533371\n",
      "└ @ Main /home/hebi/git/DAG-EQ/src/train.jl:128\n",
      "┌ Info: Saving results ..\n",
      "└ @ Main In[4]:41\n",
      "┌ Info: Loading step-30000.bson ..\n",
      "└ @ Main /home/hebi/git/DAG-EQ/src/exp.jl:38\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(xdim, ydim) = (4, 3)\n",
      "(xdim, ydim) = (4, 3)\n",
      "ds = DataSetIterator[DataSetIterator:\n",
      "  batch size: 64\n",
      "  number of batches: 100\n",
      "  x data shape: (30, 30, 2, 6400)\n",
      "  y data shape: (30, 30, 6400)\n",
      "  current index: 1]\n",
      "test_ds = DataSetIterator[DataSetIterator:\n",
      "  batch size: 64\n",
      "  number of batches: 25\n",
      "  x data shape: (30, 30, 2, 1604)\n",
      "  y data shape: (30, 30, 1604)\n",
      "  current index: 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mInner testing...100%|███████████████████████████████████| Time: 0:00:01\u001b[39m\n",
      "┌ Info: data\n",
      "│   g_v = GraphMetric: prec: 0.94, recall: 0.88, shd: 5.01\n",
      "│   loss_v = 14.129029035568237\n",
      "└ @ Main /home/hebi/git/DAG-EQ/src/train.jl:128\n",
      "┌ Info: Saving results ..\n",
      "└ @ Main In[4]:41\n",
      "┌ Info: Loading step-30000.bson ..\n",
      "└ @ Main /home/hebi/git/DAG-EQ/src/exp.jl:38\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(xdim, ydim) = (4, 3)\n",
      "(xdim, ydim) = (4, 3)\n",
      "ds = DataSetIterator[DataSetIterator:\n",
      "  batch size: 64\n",
      "  number of batches: 100\n",
      "  x data shape: (40, 40, 2, 6400)\n",
      "  y data shape: (40, 40, 6400)\n",
      "  current index: 1]\n",
      "test_ds = DataSetIterator[DataSetIterator:\n",
      "  batch size: 64\n",
      "  number of batches: 25\n",
      "  x data shape: (40, 40, 2, 1604)\n",
      "  y data shape: (40, 40, 1604)\n",
      "  current index: 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mInner testing...100%|███████████████████████████████████| Time: 0:00:07\u001b[39m\n",
      "┌ Info: data\n",
      "│   g_v = GraphMetric: prec: 0.93, recall: 0.87, shd: 7.56\n",
      "│   loss_v = 20.937103867530823\n",
      "└ @ Main /home/hebi/git/DAG-EQ/src/train.jl:128\n",
      "┌ Info: Saving results ..\n",
      "└ @ Main In[4]:41\n"
     ]
    }
   ],
   "source": [
    "test_unseen_d()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "test_unseen_d_2 (generic function with 1 method)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test the individual trained models\n",
    "# d=10,15,20\n",
    "# on larger d\n",
    "function test_unseen_d_2()\n",
    "    for ID in [\"EQ2-ERSF-k1-d=10-ensemble\", \"EQ2-ERSF-k1-d=15-ensemble\", \"EQ2-ERSF-k1-d=20-ensemble\"],\n",
    "        d in [10, 15, 20, 30, 40, 50, 80, 100]\n",
    "\n",
    "        specs = []\n",
    "\n",
    "        for gtype in [:ER, :SF],\n",
    "            k in [1]\n",
    "            push!(specs, DataSpec(d=d, k=k, gtype=gtype,\n",
    "                                  noise=:Gaussian, mat=:CH3))\n",
    "        end\n",
    "        specs = Array{DataSpec}(specs)\n",
    "\n",
    "        exp_test(ID, specs, \"TEST-d=$d\")\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Loading step-30000.bson ..\n",
      "└ @ Main /home/hebi/git/DAG-EQ/src/exp.jl:38\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(xdim, ydim) = (4, 3)\n",
      "(xdim, ydim) = (4, 3)\n",
      "ds = DataSetIterator[DataSetIterator:\n",
      "  batch size: 64\n",
      "  number of batches: 225\n",
      "  x data shape: (10, 10, 2, 14400)\n",
      "  y data shape: (10, 10, 14400)\n",
      "  current index: 1]\n",
      "test_ds = DataSetIterator[DataSetIterator:\n",
      "  batch size: 64\n",
      "  number of batches: 56\n",
      "  x data shape: (10, 10, 2, 3606)\n",
      "  y data shape: (10, 10, 3606)\n",
      "  current index: 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Warning: calls to Base intrinsics might be GPU incompatible\n",
      "│   exception = (GPUCompiler.MethodSubstitutionWarning(log1p(x::Float32) in Base.Math at special/log.jl:360, log1p(x::Float32) in CUDA at /home/hebi/.julia/packages/CUDA/YeS8q/src/device/intrinsics/math.jl:85), Base.StackTraces.StackFrame[log1p at log.jl:360, broadcast_kernel at broadcast.jl:59])\n",
      "└ @ GPUCompiler /home/hebi/.julia/packages/GPUCompiler/uTpNx/src/irgen.jl:68\n",
      "\u001b[32mInner testing...100%|███████████████████████████████████| Time: 0:00:21\u001b[39m\n",
      "┌ Info: data\n",
      "│   g_v = GraphMetric: prec: 0.98, recall: 0.93, shd: 0.81\n",
      "│   loss_v = 2.2192376479506493\n",
      "└ @ Main /home/hebi/git/DAG-EQ/src/train.jl:128\n",
      "┌ Info: Saving results ..\n",
      "└ @ Main /home/hebi/git/DAG-EQ/src/exp.jl:293\n",
      "┌ Info: Loading step-30000.bson ..\n",
      "└ @ Main /home/hebi/git/DAG-EQ/src/exp.jl:38\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(xdim, ydim) = (4, 3)\n",
      "(xdim, ydim) = (4, 3)\n",
      "ds = DataSetIterator[DataSetIterator:\n",
      "  batch size: 64\n",
      "  number of batches: 225\n",
      "  x data shape: (15, 15, 2, 14400)\n",
      "  y data shape: (15, 15, 14400)\n",
      "  current index: 1]\n",
      "test_ds = DataSetIterator[DataSetIterator:\n",
      "  batch size: 64\n",
      "  number of batches: 56\n",
      "  x data shape: (15, 15, 2, 3606)\n",
      "  y data shape: (15, 15, 3606)\n",
      "  current index: 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mInner testing...100%|███████████████████████████████████| Time: 0:00:03\u001b[39m\n",
      "┌ Info: data\n",
      "│   g_v = GraphMetric: prec: 0.81, recall: 0.92, shd: 4.17\n",
      "│   loss_v = 18.319161772727966\n",
      "└ @ Main /home/hebi/git/DAG-EQ/src/train.jl:128\n",
      "┌ Info: Saving results ..\n",
      "└ @ Main /home/hebi/git/DAG-EQ/src/exp.jl:293\n",
      "┌ Info: Loading step-30000.bson ..\n",
      "└ @ Main /home/hebi/git/DAG-EQ/src/exp.jl:38\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(xdim, ydim) = (4, 3)\n",
      "(xdim, ydim) = (4, 3)\n",
      "ds = DataSetIterator[DataSetIterator:\n",
      "  batch size: 64\n",
      "  number of batches: 225\n",
      "  x data shape: (20, 20, 2, 14400)\n",
      "  y data shape: (20, 20, 14400)\n",
      "  current index: 1]\n",
      "test_ds = DataSetIterator[DataSetIterator:\n",
      "  batch size: 64\n",
      "  number of batches: 56\n",
      "  x data shape: (20, 20, 2, 3606)\n",
      "  y data shape: (20, 20, 3606)\n",
      "  current index: 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mInner testing...100%|███████████████████████████████████| Time: 0:00:01\u001b[39m\n",
      "┌ Info: data\n",
      "│   g_v = GraphMetric: prec: 0.63, recall: 0.85, shd: 12.35\n",
      "│   loss_v = 86.0452790260315\n",
      "└ @ Main /home/hebi/git/DAG-EQ/src/train.jl:128\n",
      "┌ Info: Saving results ..\n",
      "└ @ Main /home/hebi/git/DAG-EQ/src/exp.jl:293\n",
      "┌ Info: Loading step-30000.bson ..\n",
      "└ @ Main /home/hebi/git/DAG-EQ/src/exp.jl:38\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(xdim, ydim) = (4, 3)\n",
      "(xdim, ydim) = (4, 3)\n",
      "ds = DataSetIterator[DataSetIterator:\n",
      "  batch size: 64\n",
      "  number of batches: 100\n",
      "  x data shape: (30, 30, 2, 6400)\n",
      "  y data shape: (30, 30, 6400)\n",
      "  current index: 1]\n",
      "test_ds = DataSetIterator[DataSetIterator:\n",
      "  batch size: 64\n",
      "  number of batches: 25\n",
      "  x data shape: (30, 30, 2, 1604)\n",
      "  y data shape: (30, 30, 1604)\n",
      "  current index: 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mInner testing...100%|███████████████████████████████████| Time: 0:00:02\u001b[39m\n",
      "┌ Info: data\n",
      "│   g_v = GraphMetric: prec: 0.43, recall: 0.64, shd: 35.33\n",
      "│   loss_v = 349.3854694366455\n",
      "└ @ Main /home/hebi/git/DAG-EQ/src/train.jl:128\n",
      "┌ Info: Saving results ..\n",
      "└ @ Main /home/hebi/git/DAG-EQ/src/exp.jl:293\n",
      "┌ Info: Loading step-30000.bson ..\n",
      "└ @ Main /home/hebi/git/DAG-EQ/src/exp.jl:38\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(xdim, ydim) = (4, 3)\n",
      "(xdim, ydim) = (4, 3)\n",
      "ds = DataSetIterator[DataSetIterator:\n",
      "  batch size: 64\n",
      "  number of batches: 100\n",
      "  x data shape: (40, 40, 2, 6400)\n",
      "  y data shape: (40, 40, 6400)\n",
      "  current index: 1]\n",
      "test_ds = DataSetIterator[DataSetIterator:\n",
      "  batch size: 64\n",
      "  number of batches: 25\n",
      "  x data shape: (40, 40, 2, 1604)\n",
      "  y data shape: (40, 40, 1604)\n",
      "  current index: 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mInner testing...100%|███████████████████████████████████| Time: 0:00:07\u001b[39m\n",
      "┌ Info: data\n",
      "│   g_v = GraphMetric: prec: 0.33, recall: 0.49, shd: 59.18\n",
      "│   loss_v = 680.2563629150391\n",
      "└ @ Main /home/hebi/git/DAG-EQ/src/train.jl:128\n",
      "┌ Info: Saving results ..\n",
      "└ @ Main /home/hebi/git/DAG-EQ/src/exp.jl:293\n",
      "┌ Info: Loading step-30000.bson ..\n",
      "└ @ Main /home/hebi/git/DAG-EQ/src/exp.jl:38\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(xdim, ydim) = (4, 3)\n",
      "(xdim, ydim) = (4, 3)\n",
      "ds = DataSetIterator[DataSetIterator:\n",
      "  batch size: 32\n",
      "  number of batches: 50\n",
      "  x data shape: (50, 50, 2, 1600)\n",
      "  y data shape: (50, 50, 1600)\n",
      "  current index: 1]\n",
      "test_ds = DataSetIterator[DataSetIterator:\n",
      "  batch size: 32\n",
      "  number of batches: 12\n",
      "  x data shape: (50, 50, 2, 402)\n",
      "  y data shape: (50, 50, 402)\n",
      "  current index: 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mInner testing...100%|███████████████████████████████████| Time: 0:00:02\u001b[39m\n",
      "┌ Info: data\n",
      "│   g_v = GraphMetric: prec: 0.28, recall: 0.4, shd: 80.22\n",
      "│   loss_v = 1026.0891342163086\n",
      "└ @ Main /home/hebi/git/DAG-EQ/src/train.jl:128\n",
      "┌ Info: Saving results ..\n",
      "└ @ Main /home/hebi/git/DAG-EQ/src/exp.jl:293\n",
      "┌ Info: Loading step-30000.bson ..\n",
      "└ @ Main /home/hebi/git/DAG-EQ/src/exp.jl:38\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(xdim, ydim) = (4, 3)\n",
      "(xdim, ydim) = (4, 3)\n",
      "ds = DataSetIterator[DataSetIterator:\n",
      "  batch size: 32\n",
      "  number of batches: 50\n",
      "  x data shape: (80, 80, 2, 1600)\n",
      "  y data shape: (80, 80, 1600)\n",
      "  current index: 1]\n",
      "test_ds = DataSetIterator[DataSetIterator:\n",
      "  batch size: 32\n",
      "  number of batches: 12\n",
      "  x data shape: (80, 80, 2, 402)\n",
      "  y data shape: (80, 80, 402)\n",
      "  current index: 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mInner testing...100%|███████████████████████████████████| Time: 0:00:18\u001b[39m\n",
      "┌ Info: data\n",
      "│   g_v = GraphMetric: prec: 0.22, recall: 0.28, shd: 135.26\n",
      "│   loss_v = 2073.0937271118164\n",
      "└ @ Main /home/hebi/git/DAG-EQ/src/train.jl:128\n",
      "┌ Info: Saving results ..\n",
      "└ @ Main /home/hebi/git/DAG-EQ/src/exp.jl:293\n",
      "┌ Info: Loading step-30000.bson ..\n",
      "└ @ Main /home/hebi/git/DAG-EQ/src/exp.jl:38\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(xdim, ydim) = (4, 3)\n",
      "(xdim, ydim) = (4, 3)\n",
      "ds = DataSetIterator[DataSetIterator:\n",
      "  batch size: 16\n",
      "  number of batches: 100\n",
      "  x data shape: (100, 100, 2, 1600)\n",
      "  y data shape: (100, 100, 1600)\n",
      "  current index: 1]\n",
      "test_ds = DataSetIterator[DataSetIterator:\n",
      "  batch size: 16\n",
      "  number of batches: 25\n",
      "  x data shape: (100, 100, 2, 402)\n",
      "  y data shape: (100, 100, 402)\n",
      "  current index: 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mInner testing...100%|███████████████████████████████████| Time: 0:00:12\u001b[39m\n",
      "┌ Info: data\n",
      "│   g_v = GraphMetric: prec: 0.2, recall: 0.24, shd: 168.02\n",
      "│   loss_v = 2704.054183959961\n",
      "└ @ Main /home/hebi/git/DAG-EQ/src/train.jl:128\n",
      "┌ Info: Saving results ..\n",
      "└ @ Main /home/hebi/git/DAG-EQ/src/exp.jl:293\n",
      "┌ Info: Loading step-30000.bson ..\n",
      "└ @ Main /home/hebi/git/DAG-EQ/src/exp.jl:38\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(xdim, ydim) = (4, 3)\n",
      "(xdim, ydim) = (4, 3)\n",
      "ds = DataSetIterator[DataSetIterator:\n",
      "  batch size: 64\n",
      "  number of batches: 225\n",
      "  x data shape: (10, 10, 2, 14400)\n",
      "  y data shape: (10, 10, 14400)\n",
      "  current index: 1]\n",
      "test_ds = DataSetIterator[DataSetIterator:\n",
      "  batch size: 64\n",
      "  number of batches: 56\n",
      "  x data shape: (10, 10, 2, 3606)\n",
      "  y data shape: (10, 10, 3606)\n",
      "  current index: 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mInner testing...100%|███████████████████████████████████| Time: 0:00:00\u001b[39m\n",
      "┌ Info: data\n",
      "│   g_v = GraphMetric: prec: 0.98, recall: 0.69, shd: 2.99\n",
      "│   loss_v = 8.199314326047897\n",
      "└ @ Main /home/hebi/git/DAG-EQ/src/train.jl:128\n",
      "┌ Info: Saving results ..\n",
      "└ @ Main /home/hebi/git/DAG-EQ/src/exp.jl:293\n",
      "┌ Info: Loading step-30000.bson ..\n",
      "└ @ Main /home/hebi/git/DAG-EQ/src/exp.jl:38\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(xdim, ydim) = (4, 3)\n",
      "(xdim, ydim) = (4, 3)\n",
      "ds = DataSetIterator[DataSetIterator:\n",
      "  batch size: 64\n",
      "  number of batches: 225\n",
      "  x data shape: (15, 15, 2, 14400)\n",
      "  y data shape: (15, 15, 14400)\n",
      "  current index: 1]\n",
      "test_ds = DataSetIterator[DataSetIterator:\n",
      "  batch size: 64\n",
      "  number of batches: 56\n",
      "  x data shape: (15, 15, 2, 3606)\n",
      "  y data shape: (15, 15, 3606)\n",
      "  current index: 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mInner testing...100%|███████████████████████████████████| Time: 0:00:01\u001b[39m\n",
      "┌ Info: data\n",
      "│   g_v = GraphMetric: prec: 0.96, recall: 0.91, shd: 1.73\n",
      "│   loss_v = 4.770405828952789\n",
      "└ @ Main /home/hebi/git/DAG-EQ/src/train.jl:128\n",
      "┌ Info: Saving results ..\n",
      "└ @ Main /home/hebi/git/DAG-EQ/src/exp.jl:293\n",
      "┌ Info: Loading step-30000.bson ..\n",
      "└ @ Main /home/hebi/git/DAG-EQ/src/exp.jl:38\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(xdim, ydim) = (4, 3)\n",
      "(xdim, ydim) = (4, 3)\n",
      "ds = DataSetIterator[DataSetIterator:\n",
      "  batch size: 64\n",
      "  number of batches: 225\n",
      "  x data shape: (20, 20, 2, 14400)\n",
      "  y data shape: (20, 20, 14400)\n",
      "  current index: 1]\n",
      "test_ds = DataSetIterator[DataSetIterator:\n",
      "  batch size: 64\n",
      "  number of batches: 56\n",
      "  x data shape: (20, 20, 2, 3606)\n",
      "  y data shape: (20, 20, 3606)\n",
      "  current index: 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mInner testing...100%|███████████████████████████████████| Time: 0:00:01\u001b[39m\n",
      "┌ Info: data\n",
      "│   g_v = GraphMetric: prec: 0.85, recall: 0.91, shd: 4.82\n",
      "│   loss_v = 15.438900828361511\n",
      "└ @ Main /home/hebi/git/DAG-EQ/src/train.jl:128\n",
      "┌ Info: Saving results ..\n",
      "└ @ Main /home/hebi/git/DAG-EQ/src/exp.jl:293\n",
      "┌ Info: Loading step-30000.bson ..\n",
      "└ @ Main /home/hebi/git/DAG-EQ/src/exp.jl:38\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(xdim, ydim) = (4, 3)\n",
      "(xdim, ydim) = (4, 3)\n",
      "ds = DataSetIterator[DataSetIterator:\n",
      "  batch size: 64\n",
      "  number of batches: 100\n",
      "  x data shape: (30, 30, 2, 6400)\n",
      "  y data shape: (30, 30, 6400)\n",
      "  current index: 1]\n",
      "test_ds = DataSetIterator[DataSetIterator:\n",
      "  batch size: 64\n",
      "  number of batches: 25\n",
      "  x data shape: (30, 30, 2, 1604)\n",
      "  y data shape: (30, 30, 1604)\n",
      "  current index: 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mInner testing...100%|███████████████████████████████████| Time: 0:00:02\u001b[39m\n",
      "┌ Info: data\n",
      "│   g_v = GraphMetric: prec: 0.6, recall: 0.85, shd: 21.05\n",
      "│   loss_v = 140.05256700515747\n",
      "└ @ Main /home/hebi/git/DAG-EQ/src/train.jl:128\n",
      "┌ Info: Saving results ..\n",
      "└ @ Main /home/hebi/git/DAG-EQ/src/exp.jl:293\n",
      "┌ Info: Loading step-30000.bson ..\n",
      "└ @ Main /home/hebi/git/DAG-EQ/src/exp.jl:38\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(xdim, ydim) = (4, 3)\n",
      "(xdim, ydim) = (4, 3)\n",
      "ds = DataSetIterator[DataSetIterator:\n",
      "  batch size: 64\n",
      "  number of batches: 100\n",
      "  x data shape: (40, 40, 2, 6400)\n",
      "  y data shape: (40, 40, 6400)\n",
      "  current index: 1]\n",
      "test_ds = DataSetIterator[DataSetIterator:\n",
      "  batch size: 64\n",
      "  number of batches: 25\n",
      "  x data shape: (40, 40, 2, 1604)\n",
      "  y data shape: (40, 40, 1604)\n",
      "  current index: 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mInner testing...100%|███████████████████████████████████| Time: 0:00:08\u001b[39m\n",
      "┌ Info: data\n",
      "│   g_v = GraphMetric: prec: 0.45, recall: 0.75, shd: 45.39\n",
      "│   loss_v = 387.6990509033203\n",
      "└ @ Main /home/hebi/git/DAG-EQ/src/train.jl:128\n",
      "┌ Info: Saving results ..\n",
      "└ @ Main /home/hebi/git/DAG-EQ/src/exp.jl:293\n",
      "┌ Info: Loading step-30000.bson ..\n",
      "└ @ Main /home/hebi/git/DAG-EQ/src/exp.jl:38\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(xdim, ydim) = (4, 3)\n",
      "(xdim, ydim) = (4, 3)\n",
      "ds = DataSetIterator[DataSetIterator:\n",
      "  batch size: 32\n",
      "  number of batches: 50\n",
      "  x data shape: (50, 50, 2, 1600)\n",
      "  y data shape: (50, 50, 1600)\n",
      "  current index: 1]\n",
      "test_ds = DataSetIterator[DataSetIterator:\n",
      "  batch size: 32\n",
      "  number of batches: 12\n",
      "  x data shape: (50, 50, 2, 402)\n",
      "  y data shape: (50, 50, 402)\n",
      "  current index: 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mInner testing...100%|███████████████████████████████████| Time: 0:00:03\u001b[39m\n",
      "┌ Info: data\n",
      "│   g_v = GraphMetric: prec: 0.36, recall: 0.67, shd: 75.27\n",
      "│   loss_v = 703.9733924865723\n",
      "└ @ Main /home/hebi/git/DAG-EQ/src/train.jl:128\n",
      "┌ Info: Saving results ..\n",
      "└ @ Main /home/hebi/git/DAG-EQ/src/exp.jl:293\n",
      "┌ Info: Loading step-30000.bson ..\n",
      "└ @ Main /home/hebi/git/DAG-EQ/src/exp.jl:38\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(xdim, ydim) = (4, 3)\n",
      "(xdim, ydim) = (4, 3)\n",
      "ds = DataSetIterator[DataSetIterator:\n",
      "  batch size: 32\n",
      "  number of batches: 50\n",
      "  x data shape: (80, 80, 2, 1600)\n",
      "  y data shape: (80, 80, 1600)\n",
      "  current index: 1]\n",
      "test_ds = DataSetIterator[DataSetIterator:\n",
      "  batch size: 32\n",
      "  number of batches: 12\n",
      "  x data shape: (80, 80, 2, 402)\n",
      "  y data shape: (80, 80, 402)\n",
      "  current index: 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mInner testing...100%|███████████████████████████████████| Time: 0:00:20\u001b[39m\n",
      "┌ Info: data\n",
      "│   g_v = GraphMetric: prec: 0.22, recall: 0.51, shd: 185.3\n",
      "│   loss_v = 1825.2067489624023\n",
      "└ @ Main /home/hebi/git/DAG-EQ/src/train.jl:128\n",
      "┌ Info: Saving results ..\n",
      "└ @ Main /home/hebi/git/DAG-EQ/src/exp.jl:293\n",
      "┌ Info: Loading step-30000.bson ..\n",
      "└ @ Main /home/hebi/git/DAG-EQ/src/exp.jl:38\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(xdim, ydim) = (4, 3)\n",
      "(xdim, ydim) = (4, 3)\n",
      "ds = DataSetIterator[DataSetIterator:\n",
      "  batch size: 16\n",
      "  number of batches: 100\n",
      "  x data shape: (100, 100, 2, 1600)\n",
      "  y data shape: (100, 100, 1600)\n",
      "  current index: 1]\n",
      "test_ds = DataSetIterator[DataSetIterator:\n",
      "  batch size: 16\n",
      "  number of batches: 25\n",
      "  x data shape: (100, 100, 2, 402)\n",
      "  y data shape: (100, 100, 402)\n",
      "  current index: 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mInner testing...100%|███████████████████████████████████| Time: 0:00:12\u001b[39m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(xdim, ydim) = (4, 3)\n",
      "(xdim, ydim) = "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: data\n",
      "│   g_v = GraphMetric: prec: 0.18, recall: 0.46, shd: 258.03\n",
      "│   loss_v = 2489.480453491211\n",
      "└ @ Main /home/hebi/git/DAG-EQ/src/train.jl:128\n",
      "┌ Info: Saving results ..\n",
      "└ @ Main /home/hebi/git/DAG-EQ/src/exp.jl:293\n",
      "┌ Info: Loading step-30000.bson ..\n",
      "└ @ Main /home/hebi/git/DAG-EQ/src/exp.jl:38\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 3)\n",
      "ds = DataSetIterator[DataSetIterator:\n",
      "  batch size: 64\n",
      "  number of batches: 225\n",
      "  x data shape: (10, 10, 2, 14400)\n",
      "  y data shape: (10, 10, 14400)\n",
      "  current index: 1]\n",
      "test_ds = DataSetIterator[DataSetIterator:\n",
      "  batch size: 64\n",
      "  number of batches: 56\n",
      "  x data shape: (10, 10, 2, 3606)\n",
      "  y data shape: (10, 10, 3606)\n",
      "  current index: 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mInner testing...100%|███████████████████████████████████| Time: 0:00:00\u001b[39m\n",
      "┌ Info: data\n",
      "│   g_v = GraphMetric: prec: 0.94, recall: 0.34, shd: 6.32\n",
      "│   loss_v = 22.46475327014923\n",
      "└ @ Main /home/hebi/git/DAG-EQ/src/train.jl:128\n",
      "┌ Info: Saving results ..\n",
      "└ @ Main /home/hebi/git/DAG-EQ/src/exp.jl:293\n",
      "┌ Info: Loading step-30000.bson ..\n",
      "└ @ Main /home/hebi/git/DAG-EQ/src/exp.jl:38\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(xdim, ydim) = (4, 3)\n",
      "(xdim, ydim) = (4, 3)\n",
      "ds = DataSetIterator[DataSetIterator:\n",
      "  batch size: 64\n",
      "  number of batches: 225\n",
      "  x data shape: (15, 15, 2, 14400)\n",
      "  y data shape: (15, 15, 14400)\n",
      "  current index: 1]\n",
      "test_ds = DataSetIterator[DataSetIterator:\n",
      "  batch size: 64\n",
      "  number of batches: 56\n",
      "  x data shape: (15, 15, 2, 3606)\n",
      "  y data shape: (15, 15, 3606)\n",
      "  current index: 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mInner testing...100%|███████████████████████████████████| Time: 0:00:01\u001b[39m\n",
      "┌ Info: data\n",
      "│   g_v = GraphMetric: prec: 0.99, recall: 0.76, shd: 3.57\n",
      "│   loss_v = 9.685962200164795\n",
      "└ @ Main /home/hebi/git/DAG-EQ/src/train.jl:128\n",
      "┌ Info: Saving results ..\n",
      "└ @ Main /home/hebi/git/DAG-EQ/src/exp.jl:293\n",
      "┌ Info: Loading step-30000.bson ..\n",
      "└ @ Main /home/hebi/git/DAG-EQ/src/exp.jl:38\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(xdim, ydim) = (4, 3)\n",
      "(xdim, ydim) = (4, 3)\n",
      "ds = DataSetIterator[DataSetIterator:\n",
      "  batch size: 64\n",
      "  number of batches: 225\n",
      "  x data shape: (20, 20, 2, 14400)\n",
      "  y data shape: (20, 20, 14400)\n",
      "  current index: 1]\n",
      "test_ds = DataSetIterator[DataSetIterator:\n",
      "  batch size: 64\n",
      "  number of batches: 56\n",
      "  x data shape: (20, 20, 2, 3606)\n",
      "  y data shape: (20, 20, 3606)\n",
      "  current index: 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mInner testing...100%|███████████████████████████████████| Time: 0:00:01\u001b[39m\n",
      "┌ Info: data\n",
      "│   g_v = GraphMetric: prec: 0.97, recall: 0.89, shd: 2.69\n",
      "│   loss_v = 7.269417405128479\n",
      "└ @ Main /home/hebi/git/DAG-EQ/src/train.jl:128\n",
      "┌ Info: Saving results ..\n",
      "└ @ Main /home/hebi/git/DAG-EQ/src/exp.jl:293\n",
      "┌ Info: Loading step-30000.bson ..\n",
      "└ @ Main /home/hebi/git/DAG-EQ/src/exp.jl:38\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(xdim, ydim) = (4, 3)\n",
      "(xdim, ydim) = (4, 3)\n",
      "ds = DataSetIterator[DataSetIterator:\n",
      "  batch size: 64\n",
      "  number of batches: 100\n",
      "  x data shape: (30, 30, 2, 6400)\n",
      "  y data shape: (30, 30, 6400)\n",
      "  current index: 1]\n",
      "test_ds = DataSetIterator[DataSetIterator:\n",
      "  batch size: 64\n",
      "  number of batches: 25\n",
      "  x data shape: (30, 30, 2, 1604)\n",
      "  y data shape: (30, 30, 1604)\n",
      "  current index: 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mInner testing...100%|███████████████████████████████████| Time: 0:00:02\u001b[39m\n",
      "┌ Info: data\n",
      "│   g_v = GraphMetric: prec: 0.79, recall: 0.9, shd: 9.91\n",
      "│   loss_v = 39.9320330619812\n",
      "└ @ Main /home/hebi/git/DAG-EQ/src/train.jl:128\n",
      "┌ Info: Saving results ..\n",
      "└ @ Main /home/hebi/git/DAG-EQ/src/exp.jl:293\n",
      "┌ Info: Loading step-30000.bson ..\n",
      "└ @ Main /home/hebi/git/DAG-EQ/src/exp.jl:38\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(xdim, ydim) = (4, 3)\n",
      "(xdim, ydim) = (4, 3)\n",
      "ds = DataSetIterator[DataSetIterator:\n",
      "  batch size: 64\n",
      "  number of batches: 100\n",
      "  x data shape: (40, 40, 2, 6400)\n",
      "  y data shape: (40, 40, 6400)\n",
      "  current index: 1]\n",
      "test_ds = DataSetIterator[DataSetIterator:\n",
      "  batch size: 64\n",
      "  number of batches: 25\n",
      "  x data shape: (40, 40, 2, 1604)\n",
      "  y data shape: (40, 40, 1604)\n",
      "  current index: 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mInner testing...100%|███████████████████████████████████| Time: 0:00:07\u001b[39m\n",
      "┌ Info: data\n",
      "│   g_v = GraphMetric: prec: 0.66, recall: 0.87, shd: 22.95\n",
      "│   loss_v = 135.37900114059448\n",
      "└ @ Main /home/hebi/git/DAG-EQ/src/train.jl:128\n",
      "┌ Info: Saving results ..\n",
      "└ @ Main /home/hebi/git/DAG-EQ/src/exp.jl:293\n",
      "┌ Info: Loading step-30000.bson ..\n",
      "└ @ Main /home/hebi/git/DAG-EQ/src/exp.jl:38\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(xdim, ydim) = (4, 3)\n",
      "(xdim, ydim) = (4, 3)\n",
      "ds = DataSetIterator[DataSetIterator:\n",
      "  batch size: 32\n",
      "  number of batches: 50\n",
      "  x data shape: (50, 50, 2, 1600)\n",
      "  y data shape: (50, 50, 1600)\n",
      "  current index: 1]\n",
      "test_ds = DataSetIterator[DataSetIterator:\n",
      "  batch size: 32\n",
      "  number of batches: 12\n",
      "  x data shape: (50, 50, 2, 402)\n",
      "  y data shape: (50, 50, 402)\n",
      "  current index: 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mInner testing...100%|███████████████████████████████████| Time: 0:00:02\u001b[39m\n",
      "┌ Info: data\n",
      "│   g_v = GraphMetric: prec: 0.57, recall: 0.83, shd: 39.4\n",
      "│   loss_v = 278.22453117370605\n",
      "└ @ Main /home/hebi/git/DAG-EQ/src/train.jl:128\n",
      "┌ Info: Saving results ..\n",
      "└ @ Main /home/hebi/git/DAG-EQ/src/exp.jl:293\n",
      "┌ Info: Loading step-30000.bson ..\n",
      "└ @ Main /home/hebi/git/DAG-EQ/src/exp.jl:38\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(xdim, ydim) = (4, 3)\n",
      "(xdim, ydim) = (4, 3)\n",
      "ds = DataSetIterator[DataSetIterator:\n",
      "  batch size: 32\n",
      "  number of batches: 50\n",
      "  x data shape: (80, 80, 2, 1600)\n",
      "  y data shape: (80, 80, 1600)\n",
      "  current index: 1]\n",
      "test_ds = DataSetIterator[DataSetIterator:\n",
      "  batch size: 32\n",
      "  number of batches: 12\n",
      "  x data shape: (80, 80, 2, 402)\n",
      "  y data shape: (80, 80, 402)\n",
      "  current index: 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mInner testing...100%|███████████████████████████████████| Time: 0:00:18\u001b[39m\n",
      "┌ Info: data\n",
      "│   g_v = GraphMetric: prec: 0.43, recall: 0.72, shd: 97.04\n",
      "│   loss_v = 769.8894233703613\n",
      "└ @ Main /home/hebi/git/DAG-EQ/src/train.jl:128\n",
      "┌ Info: Saving results ..\n",
      "└ @ Main /home/hebi/git/DAG-EQ/src/exp.jl:293\n",
      "┌ Info: Loading step-30000.bson ..\n",
      "└ @ Main /home/hebi/git/DAG-EQ/src/exp.jl:38\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(xdim, ydim) = (4, 3)\n",
      "(xdim, ydim) = (4, 3)\n",
      "ds = DataSetIterator[DataSetIterator:\n",
      "  batch size: 16\n",
      "  number of batches: 100\n",
      "  x data shape: (100, 100, 2, 1600)\n",
      "  y data shape: (100, 100, 1600)\n",
      "  current index: 1]\n",
      "test_ds = DataSetIterator[DataSetIterator:\n",
      "  batch size: 16\n",
      "  number of batches: 25\n",
      "  x data shape: (100, 100, 2, 402)\n",
      "  y data shape: (100, 100, 402)\n",
      "  current index: 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mInner testing...100%|███████████████████████████████████| Time: 0:00:12\u001b[39m\n",
      "┌ Info: data\n",
      "│   g_v = GraphMetric: prec: 0.39, recall: 0.66, shd: 137.13\n",
      "│   loss_v = 1083.8699226379395\n",
      "└ @ Main /home/hebi/git/DAG-EQ/src/train.jl:128\n",
      "┌ Info: Saving results ..\n",
      "└ @ Main /home/hebi/git/DAG-EQ/src/exp.jl:293\n"
     ]
    }
   ],
   "source": [
    "test_unseen_d_2()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test on different noise and the tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function test_different_noise()\n",
    "    # FIXME OOM for d=100??\n",
    "    for d in [10,20,50,100],\n",
    "        noise in [:Gaussian, :Poisson, :Exp, :Gumbel]\n",
    "\n",
    "        ID = \"EQ2-ERSF-k1-d=$d-ensemble\"\n",
    "\n",
    "        specs = []\n",
    "        for gtype in [:ER, :SF],\n",
    "            k in [1]\n",
    "            push!(specs, DataSpec(d=d, k=k, gtype=gtype,\n",
    "                    noise=noise, mat=:CH3))\n",
    "        end\n",
    "        specs = Array{DataSpec}(specs)\n",
    "        \n",
    "        @info \"Testing on\" ID d noise\n",
    "        exp_test(ID, specs, \"TEST-d=$d-noise=$noise\")\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_different_noise()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sachs 2005 experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and explore the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = CSV.read(\"Sachs/1.cd3cd28.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SachsX = convert(Matrix, df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "include(\"data_graph.jl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SachsG = Sachs_ground_truth()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "myplot(SachsG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "medcovX = cov(SachsX) ./ median(var(SachsX, dims=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxcovX = cov(SachsX) ./ maximum(var(SachsX, dims=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corX = cor(SachsX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ch2X = getch2(SachsX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "include(\"exp.jl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the trained model\n",
    "@load \"saved_models/EQ-d=20_k=1_gtype=SF_noise=Gaussian_mat=medCOV_mec=Linear/step-15000.bson\" model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@load \"saved_models/EQ-d=10_k=1_gtype=ER_noise=Gaussian_mat=medCOV_mec=Linear/step-15000.bson\" model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@load \"back/back-0907/CORCOV/EQ-d=10_k=1_gtype=SF_noise=Gaussian_mat=COR_mec=Linear/step-15000.bson\" model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@load \"saved_models/ensK-2020-09-08T10:58:41.247-ensemble/step-10000.bson\" model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The new ensemble model\n",
    "@load \"saved_models/ensemEQ-ICLR-1-ensemble/step-159443.bson\" model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@load \"saved_models/ensemEQ-CH2-1,2,4-2020-10-11T11:29:01.183-ensemble/step-100000.bson\" model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = inf_one(model, medcovX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = inf_one(model, corX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = inf_one(model, maxcovX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = inf_one(model, ch2X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Wout = threshold(σ.(out), 0.3, true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "myplot(DiGraph(Wout), names(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FIXME NOW !!!! the names might not match at all!!!\n",
    "myplot(SachsG, names(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predicted edge, true edge, SHD\n",
    "predicted_edge = ne(DiGraph(Wout))\n",
    "@show predicted_edge\n",
    "correct_edge = sum(Wout[Wout .== 1] .== adjacency_matrix(SachsG)[Wout .== 1])\n",
    "@show correct_edge\n",
    "\n",
    "# metrics\n",
    "ytrue = Matrix(gen_weights(SachsG))\n",
    "sup_graph_metrics(Wout, ytrue)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO calculate #reverse direction edges\n",
    "sum(Wout[Wout .== 1] .== adjacency_matrix(SachsG)[Wout .== 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(Wout'[Wout' .== 1] .== adjacency_matrix(SachsG)[Wout' .== 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO implement the recursive add procedure to remove cycles\n",
    "# Or, just construct the graph, and keep removing until it is a DAG\n",
    "is_cyclic(DiGraph(Wout))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Wout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Or just implement the procedure\n",
    "out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding non-cyclic procedure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Wout2 = threshold(σ.(out), 0.3, false)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find the order of the index, or, sort the indexes\n",
    "sort(Wout2, dims=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edgeidx = findall((x)->x>0, Wout2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_idx = edgeidx[sortperm(Wout2[edgeidx], rev=true)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Wout2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add sorted idx\n",
    "g = MetaDiGraph(11)\n",
    "for idx in sorted_idx\n",
    "    add_edge!(g, idx[1], idx[2])\n",
    "    if is_cyclic(g)\n",
    "        rem_edge!(g, idx[1], idx[2])\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p1 = myplot(g, names(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "draw(PNG(\"p1.png\"), p1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p0 = myplot(SachsG, names(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "draw(PNG(\"p0.png\"), p0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adj1 = adjacency_matrix(g)\n",
    "adj0 = adjacency_matrix(SachsG)\n",
    "# predicted edge, true edge, SHD\n",
    "predicted_edge = ne(g)\n",
    "@show predicted_edge\n",
    "correct_edge = sum(adj1[adj1 .== 1] .== adj0[adj1 .== 1])\n",
    "@show correct_edge\n",
    "reversed_edge = sum(adj1'[adj1' .== 1] .== adj0[adj1' .== 1])\n",
    "@show reversed_edge\n",
    "\n",
    "# metrics\n",
    "ytrue = Matrix(gen_weights(SachsG))\n",
    "sup_graph_metrics(adj1, ytrue)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## More data\n",
    "\n",
    "- [ ] goblinop's gaussian data (just for test)\n",
    "- [ ] bnlearn's continous data\n",
    "- [ ] discrete data?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### goblinop's (??) gaussian data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = CSV.read(\"data-back/gaussian.dat\", delim=\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = convert(Matrix, df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "include(\"data_graph.jl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxcovX = cov(X) ./ maximum(var(X, dims=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "include(\"exp.jl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The new ensemble model\n",
    "@load \"saved_models/ensemEQ-ICLR-1-ensemble/step-159443.bson\" model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = inf_one(model, maxcovX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Wout2 = threshold(σ.(out), 0.3, false)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find the order of the index, or, sort the indexes\n",
    "sort(Wout2, dims=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edgeidx = findall((x)->x>0, Wout2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_idx = edgeidx[sortperm(Wout2[edgeidx], rev=true)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Wout2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "size(X,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add sorted idx\n",
    "g = MetaDiGraph(size(X,2))\n",
    "for idx in sorted_idx\n",
    "    add_edge!(g, idx[1], idx[2])\n",
    "    if is_cyclic(g)\n",
    "        rem_edge!(g, idx[1], idx[2])\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bnp1 = myplot(g, [\"A\", \"B\", \"C\", \"D\", \"E\", \"F\", \"G\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function bnlearn_ground_truth()\n",
    "    greal = named_graph([:A, :B, :C, :D, :E, :F, :G])\n",
    "    named_graph_add_edge!(greal, :B, :C)\n",
    "    named_graph_add_edge!(greal, :A, :C)\n",
    "    named_graph_add_edge!(greal, :B, :D)\n",
    "    named_graph_add_edge!(greal, :D, :F)\n",
    "    named_graph_add_edge!(greal, :A, :F)\n",
    "    named_graph_add_edge!(greal, :G, :F)\n",
    "    named_graph_add_edge!(greal, :E, :F)\n",
    "    greal\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "groundG = bnlearn_ground_truth()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bnp0 = myplot(groundG, [\"A\", \"B\", \"C\", \"D\", \"E\", \"F\", \"G\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "draw(PNG(\"bnp0.png\"), bnp0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "draw(PNG(\"bnp1.png\"), bnp1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adj1 = adjacency_matrix(g)\n",
    "adj0 = adjacency_matrix(groundG)\n",
    "# predicted edge, true edge, SHD\n",
    "predicted_edge = ne(g)\n",
    "@show predicted_edge\n",
    "correct_edge = sum(adj1[adj1 .== 1] .== adj0[adj1 .== 1])\n",
    "@show correct_edge\n",
    "reversed_edge = sum(adj1'[adj1' .== 1] .== adj0[adj1' .== 1])\n",
    "@show reversed_edge\n",
    "\n",
    "# metrics\n",
    "ytrue = Matrix(gen_weights(groundG))\n",
    "sup_graph_metrics(adj1, ytrue)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.5.3",
   "language": "julia",
   "name": "julia-1.5"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.5.3"
  },
  "toc-autonumbering": true
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
